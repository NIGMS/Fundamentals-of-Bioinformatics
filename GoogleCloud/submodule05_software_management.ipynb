{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1553273d-c130-4398-8256-2d3d7b2aa66a",
   "metadata": {},
   "source": [
    "# Installing and Managing Bioinformatic Software\n",
    "\n",
    "------\n",
    "### Learning Objectives:\n",
    "\n",
    "+ Create a conda environment with a yml file\n",
    "\n",
    "+ Build and add to a conda environment with a list of software\n",
    "\n",
    "+ Discuss basic quality metrics for FASTQ files\n",
    "\n",
    "## Accessing Bioinformatic Software \n",
    "-----\n",
    "\n",
    "Bioinformatic software can be installed and managed in a number of ways. It is important to keep track of software versions so that you can report what was used for specific analyses/projects. Similar to how you would report the methods of a bench experiment, you should report any information about a bioinformatic analysis that would enable another researcher to repeat the experiment that you performed and get the same or very similar results. This includes the source of the data you used, the version of the software used, any arguments or settings that were used during the analysis. \n",
    "\n",
    "### Software Pre-Installed on the System\n",
    "Linux systems will have many core utilities for navigating the file system, creating, editing and removing files, downloading and uploading files, and many more.  These utilities are commonly found in `/usr/bin`. Commands that we have been using like `ls` or `cd` are examples of software that are pre-installed in the system. To get an idea of the software that are pre-installed use the command `ls /usr/bin/` (make sure you've enabled the option for scrolling on the results by right clicking on the notebook and selecting *Enable Scrolling for Outputs*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512d35f-0bd3-44da-8b49-07e4891d888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# List preinstalled software\n",
    "ls /usr/bin/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddf503-c368-4a2b-8041-fdbdf4e97e2d",
   "metadata": {},
   "source": [
    "\n",
    "### Full Package and Environment Management (e.g. Conda, Mambaforge)\n",
    "\n",
    "[Conda](https://docs.conda.io/projects/conda/en/latest/) is an open source package and environment manager that runs on Windows, MacOS, and Linux. Conda allows you to install and update software packages as well as organize them efficiently into *environments* that you can switch between to manage software collections and versions. \n",
    "\n",
    "One way you might use these environments is to create an environment for each type of analysis you might perform, one environment could be for RNAseq preprocessing and another environment could be for variant calling. Conda allows you to create a virtually unlimited number of software environments that can be used for specific analyses, and therefore presents efficient and reproducible way to manage your software across multiple projects. Importantly, Conda also enables you to share environments with others interested in replicating an analysis you've performed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c316cac-4b03-4359-8b4c-e83a6491bd92",
   "metadata": {},
   "source": [
    "## Getting Started with Conda in Jupyter Notebooks\n",
    "--------\n",
    "\n",
    "In this lesson we will create a conda environment and install software that will enable us to check the quality of some FASTQ files. However, before we can create our conda environment we need to give the conda software permission to create environments within our Jupyter notebook. Within the Jupyter notebook each conda environment will be established in a kernel, a kernel is a piece of software that controls the interactions of the hardware (processors and memory) and the software. Each conda environment will have different suite of software packages and so each environment will need it's own kernel to direct these interactions. \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/kernel.png\" alt=\"kernel\" width=\"30%\"/>\n",
    "</p>\n",
    "\n",
    "<span style=\"color:black\">Learn more about how to use json format files for bioinformatics in [this video](https://www.youtube.com/watch?v=ETlPFgyn5DY&list=PLXaEJPtnQ4w7Vu7vqWbttBjUGrPp4Qa7b&index=6).</span>\n",
    "\n",
    "Before we can create conda environments we need to enable the conda software to create kernels. We are going to do this with a script stored in the Jupyter config directory, this is a directory that stores code to guide the behavior of the notebook. We can find the path of this directory with the command `jupyter --config-dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3a50a-bc28-43d9-8d44-9880e8da1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## let's look at the contents of our working directory\n",
    "jupyter --config-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712d9a8-c807-43ee-b486-27dc01b7d088",
   "metadata": {},
   "source": [
    "cd into the directory outputed from the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4253397-2a58-4ebf-bf34-e89fd387d9d6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "    <b>Alert: </b>  The following steps require that you use the terminal\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d17bb9-b344-46be-b984-a9256572c5c6",
   "metadata": {},
   "source": [
    "Within this directory we will create a script to guide the notebook to create a kernel for each conda environment. Follow the steps below in the terminal window. \n",
    "\n",
    "1. Create a file called `jupyter_config.json`  with the `nano` text editor using the command `nano jupyter_config.json`\n",
    "2. Copy and paste the following text into your text editor window:\n",
    "\n",
    "   \n",
    " >  \n",
    "    {\n",
    "      \"CondaKernelSpecManager\": {\n",
    "        \"kernelspec_path\": \"--user\"\n",
    "      }\n",
    "    }\n",
    "    \n",
    "\n",
    "3. Use the `ctrl + x` keys to exit the text editor\n",
    "4. Type `y` to save the changes you've made, and `return` to write them to the file. \n",
    "\n",
    "\n",
    "Now we can double check that the file exists and the text in the file matches what you should have copied above with the `cat` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a1d22-d5b8-4b71-83f7-d1cae217400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check the the file exists and the contents of the file match the text above\n",
    "cat ~/.jupyter/jupyter_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc4dad-2c75-49c0-99aa-459a730d3209",
   "metadata": {},
   "source": [
    "Run the following commands to jump start the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5fd0a-ed71-4fbf-82fa-0d40cbb3533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install nb_conda_kernels. Sometimes this command will error out. If it does, try again.\n",
    "conda install -c conda-forge nb_conda_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01931d3-9643-4f77-946c-cad907a6613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m nb_conda_kernels list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a2d00-2c77-4674-90ce-f7d25a05894b",
   "metadata": {},
   "source": [
    "You have now allowed conda to create kernels for any conda environment you create within the notebook. \n",
    "\n",
    "To ensure that the script has been added properly go to `File` and select `New Launcher`. You should see a new kernel named __Python [conda env:root]__ this is your root conda environment as a Jupyter kernel.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/condaRoot.png\" alt=\"condaRoot\" width=\"20%\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbba69b-a7e7-4961-bb89-d0dcb5c2a670",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "    <b>Alert: </b> You may not see the conda:env_root kernel, if you don't try refreshing the notebook page. Sometimes it can take a few minutes to load.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e21a1b-c662-4d9c-856b-a800bbf1f853",
   "metadata": {},
   "source": [
    "## Creating a Conda Environment\n",
    "--------\n",
    "\n",
    "Now that we can set up kernels we are ready to begin creating conda environments. There are two ways to create a conda environment, you can create an environment by specifying the name of the environment and the name of the software that you would like installed or you can create an environment from a yml file, which is a file that contains a list of all software that should be installed. let's start with installing from a yml file, in your home directory we have created a file called `env.yml` let's take a minute to look inside this file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3b0aa-4abb-4ebe-bf44-d4c838521bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Print the contents of the yml file to the screen\n",
    "cat env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07328af1-53fa-4973-a4f0-a79cb7e93dbf",
   "metadata": {},
   "source": [
    "You can see that the file has three components the `name:`, the `channels:`, and the `dependencies:` \n",
    "\n",
    "The `name` component indicates the name for the conda environment to be created, in this case the environment will be called **test_env**. \n",
    "\n",
    "The `channels` component proceeds a list indicating the locations of the software packages to be installed. Conda packages are downloaded from remote locations called channels, which are URLs to directories containing conda packages. This file specifies that the packages can be found on the *bioconda* channel, a popular channel for bioinformatic software packages.\n",
    "\n",
    "The third component is the `dependencies` which proceeds a list containing the software packages to be installed in the environment. Here we are installing python version 3.9, ipykernel, and fastqc. You can see that the version of python is specified with the equal sign. \n",
    "\n",
    "*When creating conda environments in Jupyter notebook you must have the ipykernel software in the environment to ensure that the conda environment is created as a kernel within the notebook.*\n",
    "\n",
    "To create a file using the `env.yml` file we can use the command `conda env create` with the flag `--file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c88854-fdf5-43b9-a81b-ce0bc3efe3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a new conda environment from a yml file\n",
    "conda env create --file env.yml\n",
    "\n",
    "## This command should take between 1-5 minutes, it took me about a minute and a half to run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7d52c-9f07-4a48-bcac-49409ce898ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  Warning this command can take a while to download all the software and their dependencies.\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f8f1c-935f-4e1c-a7dc-a44ddbeff740",
   "metadata": {},
   "source": [
    "This command has created the conda environment named **test_env** which contains the software specified in the yml file. \n",
    "\n",
    "To switch to your new conda environment click on your current kernel located in the top righthand corner (e.g. Python 3, Python [conda env:root], etc.) locate your new conda environment and click __Select__. \n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/selectKernel.png\" alt=\"selectKernel\" width=\"30%\"/>\n",
    "</p>\n",
    "\n",
    "In the terminal to activate a conda environment use the command `conda activate test_env`. You will see in parentheses before your prompt the text will change from `base` to `test_env`. If you are not sure what conda environments are available for you to load (or you forgot the spelling of the environment name) you can use the command `conda env list` to list the names of the available conda environments.\n",
    "\n",
    "To ensure that your conda environment is activated let's list the available software with the command `conda list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9642a1e-5154-44b9-990f-5dc5209ae0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## List software packages currently available in the loaded conda environment\n",
    "conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886f04c-1bb0-4059-86ff-5cdcc2854fea",
   "metadata": {},
   "source": [
    "You can see that in addition to the software listed in the yml file there are many additional software that have been installed. These are the software dependencies that are required to use the software programs we specified in the yml file. This is one of the strengths of using a package manager like conda, the appropriate version of each dependency required for the specified software are automatically added to your environment.  \n",
    "\n",
    "If you do not have a yml file that specifies the software needed for an analysis you can create conda environments by listing the software you would like installed with the `conda create` command. Here we use the `-n` flag to specify the name of our environment, the `--channel` flag to specify the channel software packages should be loaded from, and the names of the software as the argument for the command.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c54ef1-6cf6-4d53-af7d-8d37cbe1bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## You can create a new environment with all software to be installed in a single command\n",
    "conda create -n test --channel bioconda python=3.9 ipykernel fastqc -y\n",
    "\n",
    "# I know we are missing multiQC in this list of software.. we will get to that later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5bed7-887d-4dd2-ab58-8d250a6069af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "    <b>Alert: </b> Switch back to the Python 3 kernel to use the command below to jump start the conda kernel process. Otherwise you will get a \"No module named nb_conda_kernels\" error.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689ef6a-6cca-459e-adf3-d987c4f4b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jump start conda kernel process\n",
    "#%%bash\n",
    "\n",
    "!python -m nb_conda_kernels list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c9d0c-8c1b-481b-b41c-138d12d51df6",
   "metadata": {},
   "source": [
    "It is easy enough to enter this command manually if you have only a small number of packages to be installed, but the command can get unwieldy if there are many packages to be installed. Furthermore, having the yml file creates some record of how the environment was created and enables you to share the file with others who may want to create and use the same environment.\n",
    "\n",
    "## Modifying a Conda Environment\n",
    "------\n",
    "\n",
    "Generally once a conda environment is created it won't need to be modified for as long as the analysis pipeline is stable. However there are times when software will need to be added, or versions of software might need to be updated. For the purpose of this lesson I have left one of the software packages, `multiQC`, off of the list of dependencies in the yml file. let's add this package to our environment now with the `conda install` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149e564-2bfc-4b2e-99f9-ac3f2b6a499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Add MultiQC software to the conda environment\n",
    "conda install --channel bioconda multiqc -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9f9c5-3db9-4b2c-9359-8d713ce6179d",
   "metadata": {},
   "source": [
    "Now that we have a complete conda environment with all the software and dependencies we need we should update the yml file to keep a record of the software versions in the environment. The yml file can also be used to share the environment with others who can reproduce our analyses using the same software versions. \n",
    "\n",
    "To create a yml file we use the `cond env export` command with a redirect `>` to save the formatted yml output to a file we can share with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184875b-d553-4c32-83ba-6b7bc66a1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "# Now generate an updated yml file to keep accurate records about the contents of the conda environment\n",
    "conda env export > new_env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1bcd5-7a27-4504-970b-e8de86ee44f9",
   "metadata": {},
   "source": [
    "## Quality Control of FastQ Files\n",
    "----------\n",
    "\n",
    "Now that we have created a conda environment let's make use of some of the tools that we installed using the looping structures that we learned about in lesson 4. The two pieces of software we will use are fastQC and multiQC, both of these softwares are for checking the quality of FASTQ files and organizing the output of quality reports to improve readability.\n",
    "\n",
    "### FastQC\n",
    "\n",
    "[FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) is an excellent tool that is specifically designed assess quality of FASTQ files . FastQC is composed of a number of analysis modules that calculate various QC metrics from FASTQ files (such as GC content, distribution of base quality, etc.) and summarizes this all into a nice QC report in HTML format, that can be opened in a web browser. Checking the quality of raw reads is important before you begin analyzing data as your analysis pipeline might have to be modified to mitigate poor quality data or contaminated data. \n",
    "\n",
    "\n",
    "<div style=\"display:flex\">\n",
    "     <div style=\"flex:1;padding-right:10px;\">\n",
    "          <img src=\"images/fastqc-good.png\" width=\"70%\"/>\n",
    "     </div>\n",
    "     <div style=\"flex:1;padding-left:10px;\">\n",
    "          <img src=\"images/fastqc-bad.png\" width=\"70%\"/>\n",
    "     </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "In the figure above is an example of a high quality FASTQ dataset on the left, and a poor quality FASTQ dataset on the right. You can see on the left panel of each image are a series of quality metrics. In the high quality data each of the metrics has a green check next to it, indicating the file has met the QC thresholds for that metric. In the poor quality FASTQ file some of the metrics have an orange exclamation point, and some have a red X indicating there are some issues with this data. \n",
    "\n",
    "Not all high quality data will pass all quality metrics, but generally high data will pass most of the QC metrics. Failed QC metrics are not an indication that you should toss the data and start over, rather they indicate that your analysis might need to be modified to mitigate some of the quality issues in the data. \n",
    "\n",
    "The first two quality metrics from the left panel, *Basic Statistics* and *Per base sequence quality* are also shown in the figures above. You can see that the basic statistics are very similar in the two reports, but there is a stark difference in per base sequence quality in the high quality dataset (left) and poor quality dataset (right).\n",
    "\n",
    "As a reminder quality scores indicate the confidence the base caller has in the base call that was made. A quality score of 30 indicates that there is a 0.1% chance that the base call is not accurate, a score of 20 indicates a 1% chance the base call is inaccurate. \n",
    "\n",
    "Ideally, most bases will be in the green region of the plots with a quality score of 28 or higher, and a very low probability of an inaccurate base call. This is what we see in the high quality data. In the poor quality data there are some bases in the high quality range, but the median base call at most positions is well below this threshold. Before analyzing data like this I would recommend trimming poor quality base calls, a step that isn't necessary in the high quality dataset. \n",
    "\n",
    "In both the high quality data and the poor quality data you can see that quality scores begin to drop off toward the end of the read. This is a known feature of Illumina sequencing data, the drop off is very slight in the high quality data. A significant dropoff as in the poor quality data might be an indication of issues with sample quality or the sequencing run. \n",
    "\n",
    "It is important to remember that FastQC expects a random and diverse library, and that a failure of any metric could be a feature of the experiment. Below is a table outlining what many of the metrics are measuring in the dataset, as well as the thresholds for failure. More information about these metrics can be found in the analysis modules section of the [FastQC manual](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/).\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>FastQC quality metrics and their thresholds for failing the QC metric.</th></tr>\n",
    "<tr><td><table></table>\n",
    "\n",
    "\n",
    "|Metric | Measurement | Failure threshold|\n",
    "|--- | --- | ---|\n",
    "|Per base sequence quality | Overall range in quality statistics by base position| lower quartile of quality score at any position is less than 5, or median less than 20 |\n",
    "|Per tile sequence quality | Only reported for Illumina data, average quality per flow cell tile| Any tile with a mean quality score 5 less than other tiles for a given base |\n",
    "|Per sequence quality score | Distribution of overall quality scores per read| Mean quality less than 20, corresponding to a 1% error rate |\n",
    "|Per base sequence content | The proportion of each base pair (ATGC) at each read position | difference in proportions of any base greater than 20%|\n",
    "|Per sequence GC content | GC content of reads in the library | The GC content of more than 30% of reads in the library deviate from the normal distribution |\n",
    "|Per base N content | Proportion of N base calls by position| more than 20% N base calls at any position|\n",
    "|Sequence length distribution | Distribution of read lengths | Any sequence has a length of 0|\n",
    "|Sequence duplication levels| Degree of duplication for each sequence, this metric only uses the first 100,000 reads | Duplicated sequences make up more than 50% of the library |\n",
    "|Overrepresented sequences| For each sequence making up 0.1% of the total library matches to common contaminants are reported| Any match makes up more than 1% of reads|\n",
    "|Adapter content| Proportion of reads with adapters detected at any position | Adapter sequences are present in more than 10% of reads |\n",
    "</td></tr> </table>\n",
    "\n",
    "\n",
    "Now that we have some familiarity with the report and how it can be use to inform your downstream analysis, let's take a look at the manual for FastQC to get an idea of the flags available to customize QC reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3979a-2147-4237-973b-7ddfd40e7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Look at the help page for fastQC\n",
    "fastqc --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70182432-e50a-4b66-a75e-7b3b0ac97123",
   "metadata": {},
   "source": [
    "In the simplest case this tool can be used by supplying a list of fastq files to be analyzed, this will work fine for most datasets. \n",
    "\n",
    "However, reading through the help page you can see that there are a number of flags that enable you to run the analysis more efficiently. For example, you can use the `-o, --output` flag to specify the name of a directory to store QC reports from the fastqc analysis. The `-t, --threads` flag accepts an integer as an argument and can be used to speed up the analysis by using multiple threads. \n",
    "\n",
    "let's run an analysis now and use the `-o` flag to designate a directory for the results called `fastqc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b018a-9538-4cce-885f-aeaf4add3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Make output directory for results\n",
    "mkdir fastqc\n",
    "\n",
    "## Run fastqc on paired reads for sample SRR1039508\n",
    "fastqc -o fastqc gcp_research_workflow/SRR1039508_1.chr20.fastq.gz gcp_research_workflow/SRR1039508_2.chr20.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f6b8e-9494-45a6-a9dc-8f9f25bc26fb",
   "metadata": {},
   "source": [
    "Take a moment to go into the fastqc file you just made and have a look at the fastqc report you generated for one of these datasets. \n",
    "\n",
    "- How do the data look, do they resemble the high quality report or the poor quality report?\n",
    "- Were any of the quality metrics flagged (orange !), or did any of them fail (red x)?\n",
    "- Were the metrics the same between the forward and reverse files?\n",
    "- Does this seem like a dataset that needs adjustment prior to an analysis, or do these data seem fairly high quality?\n",
    "\n",
    "\n",
    "\n",
    "We discussed parallelization in the first lesson, and demonstrated how it can be used to speed up an analysis. We can use the `-t` flag to parallelize a FastQC run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d98c4-5cf0-4c78-8f78-443dd4524e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Run fastqc on paired reads for sample SRR1039509 with 2 threads\n",
    "fastqc -t 2 -o fastqc gcp_research_workflow/SRR1039509_1.chr20.fastq.gz gcp_research_workflow/SRR1039509_2.chr20.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a5c00-f5fe-49cf-8331-931d469685af",
   "metadata": {},
   "source": [
    "You will notice that in the first run where we only used one thread the output indicated that the analysis analyzed each file sequentially, whereas when we used two threads the files were analyzed in parallel and finished at almost the same time. The parellelization in this case uses one thread per file so using more than two threads would not have sped up the analysis time.\n",
    "\n",
    "In many cases you will be analyzing a group of fastq files that will be compared downstream, in this case we have 4 samples in our group, samples SRR1039508, SRR1039509, SRR1039512, and SRR1039513. As we learned in the lesson beyond_basic_bash it can be helpful to use looping to perform the same function multiple times on a group of files. Use the code box below to write a loop that analyzes all of the fastq files in the `gcp_research_workflow` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2a032-4279-40dc-9824-825072cfc39e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-question-circle-o\" aria-hidden=\"true\"></i>\n",
    "    <b>TEST YOUR SKILLS</b> \n",
    "      <p>Practice your skills in the code block below</p>\n",
    "    <div style=\"background-color: white ; color:black; padding: 3px;\">Write a loop to analyze all fastq files in the gcp_research_workflow directory using 4 threads.<br><br>Multithreading doesn't speed up your analysis why?</div>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86432f8c-0cb7-4807-ae09-a69d4c6293f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## TEST YOUR SKILLS (enter and run your answers here)\n",
    "\n",
    "## Use a loop to analyze all fastq files in the gcp_research_workflow directory\n",
    "\n",
    "## Using 4 threads to analyze these files in a loop won't speed up your analysis, why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5027bd-498e-499e-9bca-ac380292535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"quiz_files/quiz5-1.html\", width=600, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364471e-7147-4254-9040-1bb2cba37143",
   "metadata": {},
   "source": [
    "The QC report that we looked at earlier, `SRR1039508_1.chr20_fastqc.html,` had a couple of warnings but mostly high passes. The warnings are flagged for metrics *per tile sequence quality*, *per sequence GC content*, and *sequence duplication levels*. These warnings could indicate a problem with the library or the run. If the problem was with only that sample, (ie. an issue with the library) then I would expect the same warnings to be present in the paired file `SRR1039508_2.chr20_fastqc.html` but not in other files from the same run. \n",
    "\n",
    "\n",
    "However, if the issue was with the sequencing run I would expect the warnings to be present in all samples in the group. Rather than click through each of the 8 HTML reports and compare the results we can use the software **MultiQC** to collate the results from all of our fastqc reports into one single report. \n",
    "\n",
    "let's begin by looking at the help page for the MultiQC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e9ef6-f108-486b-9dab-926a6f5be466",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Look at the help page for MultiQC\n",
    "multiqc --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e14a1a-8dab-4fef-bff5-30f3aa9568c4",
   "metadata": {},
   "source": [
    "This help page is organized nicely to blocks indicating the categories of flags that can be used to modify the analysis and summary output of the tool.\n",
    "\n",
    "Again you can see that there are several flags that would enable you to customize the report, or the tool can be run by supplying the directories with the files to be summarized listed as arguments. MultiQC also provides the option of modifying the run with a config file `--config` rather than using multiple flags at the command line to control the format of the report. The *MultiQC* config file is similar to the yml file that we used to build our conda environment in that it serves as a record of which options were used in the command to generate the report. Additionally the config file can be used many times to generate the same format report across multiple projects.\n",
    "\n",
    "Here we are going to use the simplest case and run the tool with only the flag `--flat` to suppress the creation of interactive figures which are difficult to view in Jupyter notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48625ab6-243c-4491-ba5d-66d258a86bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Run multiqc with the --flat flag to prevent interactive figures from being generated\n",
    "multiqc --flat ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395e3f9-90a0-443d-8ffe-92383f98caa4",
   "metadata": {},
   "source": [
    "\n",
    "If you double click the html file called `multiqc_report.html` you will notice as with the fastqc report there are links on the left of the file that will enable you to navigate to that section of the report quickly. Unlike the fastqc report these links are not colored according to warnings, but all samples within the directory are summarized in one single report. Perhaps more useful than flagged metrics in the fastqc report is the ability to look for consistency across samples that will be analyzed as a group. You can see in the screen shot of the report below that all samples are grouped into a single report.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/multiqc.png\" alt=\"multiqc\" width=\"80%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "We can see that there is some slight variation in sample size, but all of our samples are very high quality with base quality scores above 30 even at the end of the read. \n",
    "\n",
    "Perhaps most importantly, and easiest to see in the coallated report is that all samples are consistent with each other in all metrics, similar GC content, duplication rates, and quality score distributions. The small variation in library sizes is expected and can be mitigated with the normalization methods of most RNAseq differential expression software so should not pose a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a212eeb-7070-4643-b483-b429af3656c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "    <b>Alert: </b> To fully interact with a HTML file don't forget to click the <img src=\"images/trust_html.png\" alt=\"trust HTML\" width=\"10%\"/> button on the top left side of the HTML viewer.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
