{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1553273d-c130-4398-8256-2d3d7b2aa66a",
   "metadata": {},
   "source": [
    "# Installing and Managing Bioinformatic Software\n",
    "\n",
    "------\n",
    "### Learning Objectives:\n",
    "\n",
    "+ Create a conda environment with a yml file\n",
    "\n",
    "+ Build and add to a conda environment with a list of software\n",
    "\n",
    "+ Discuss basic quality metrics for FASTQ files\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Tip: </b>  Creating and switching between environments can be tricky, so if you're having trouble feel free to leverage Gemini (Google's advanced generative AI model) at the bottom of this module.\n",
    "</div>  \n",
    "\n",
    "## Creating a New Terminal Consoloe in Jupyter Lab\n",
    "\n",
    "Jupyter lab allows you to create a new console window within its layout. This is also possible on Jupyter lab on AWS SageMaker. Adding a terminal console window where there is a jupyter notebook tab is helpful when needing to run command line code. \n",
    "\n",
    "### 1) In Jupyter lab within a Jupyter notebook, right click on any whitespace in the notebook. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Right_click_notebook.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "### 2) Select 'New Console for Notebook'\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Right_click_notebook_highlighted.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "### 3) Select the + sign next to the new console you just made. This will open up a new launcher tab. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/New_console.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "### 4) Select Terminal under the Other section when selecting the type of launcher. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Terminal_launcher.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "This new console window can be dragged to fit elsewhere on the screen and create the desired visual. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Split_view.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "## Accessing Bioinformatic Software \n",
    "-----\n",
    "\n",
    "Bioinformatic software can be installed and managed in a number of ways. It is important to keep track of software versions so that you can report what was used for specific analyses/projects. Similar to how you would report the methods of a bench experiment, you should report any information about a bioinformatic analysis that would enable another researcher to repeat the experiment that you performed and get the same or very similar results. This includes the source of the data you used, the version of the software used, and any arguments or settings that were used during the analysis. \n",
    "\n",
    "### Software Pre-Installed on the System\n",
    "Linux systems will have many core utilities for navigating the file system, creating, editing and removing files, downloading and uploading files, and many more.  These utilities are commonly found in `/usr/bin`. Commands that we have been using like `ls` or `cd` are examples of software that are pre-installed in the system. To get an idea of the software that are pre-installed use the command `ls /usr/bin/` (make sure you've enabled the option for scrolling on the results by right clicking on the notebook and selecting *Enable Scrolling for Outputs*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512d35f-0bd3-44da-8b49-07e4891d888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# List preinstalled software\n",
    "ls /usr/bin/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddf503-c368-4a2b-8041-fdbdf4e97e2d",
   "metadata": {},
   "source": [
    "\n",
    "### Full Package and Environment Management (e.g. Conda, Mambaforge)\n",
    "\n",
    "[Conda](https://docs.conda.io/projects/conda/en/latest/) is an open source package and environment manager that runs on Windows, MacOS, and Linux. Conda allows you to install and update software packages as well as organize them efficiently into *environments* that you can switch between to manage software collections and versions. \n",
    "\n",
    "One way you might use these environments is to create an environment for each type of analysis you might perform, one environment could be for RNAseq preprocessing and another environment could be for variant calling. Conda allows you to create a virtually unlimited number of software environments that can be used for specific analyses, and therefore presents efficient and reproducible way to manage your software across multiple projects. Importantly, Conda also enables you to share environments with others interested in replicating an analysis you've performed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c316cac-4b03-4359-8b4c-e83a6491bd92",
   "metadata": {},
   "source": [
    "# Getting Started with Conda in Jupyter Notebooks\n",
    "--------\n",
    "\n",
    "In this lesson we will create a conda environment and install software that will enable us to check the quality of some FASTQ files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e21a1b-c662-4d9c-856b-a800bbf1f853",
   "metadata": {},
   "source": [
    "## Creating a Conda Environment\n",
    "--------\n",
    "\n",
    "There are two ways to create a conda environment. You can create an environment by specifying the name of the environment and the name of the software that you would like installed, or you can create an environment from a yml file, which is a file that contains a list of all software that should be installed. Let's start with installing from a yml file, in your home directory we have created a file called `env.yml`. Let's take a minute to look inside this file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3b0aa-4abb-4ebe-bf44-d4c838521bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## Print the contents of the yml file to the screen\n",
    "cat env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07328af1-53fa-4973-a4f0-a79cb7e93dbf",
   "metadata": {},
   "source": [
    "You can see that the file has three components; the `name:`, the `channels:`, and the `dependencies:` \n",
    "\n",
    "The `name` component indicates the name for the conda environment to be created, in this case the environment will be called **test_env**. \n",
    "\n",
    "The `channels` component proceeds a list indicating the locations of the software packages to be installed. Conda packages are downloaded from remote locations called channels, which are URLs to directories containing conda packages. This file specifies that the packages can be found on the *bioconda* channel, a popular channel for bioinformatic software packages.\n",
    "\n",
    "The third component is the `dependencies` which proceeds a list containing the software packages to be installed in the environment. Here we are installing python version 3.9, ipykernel, fastqc, and multiqc. You can see that the version of python is specified with the equal sign. \n",
    "\n",
    "Now switching over to the terminal, we can create a new conda environment using the `env.yml` file with the command `conda env create` and the flag `--file`. This command should take between 1-5 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7b88e-749c-4103-b822-3581c41ba2d5",
   "metadata": {},
   "source": [
    "`conda env create --file env.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7d52c-9f07-4a48-bcac-49409ce898ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  Warning this command can take a while to download all the software and their dependencies.\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f8f1c-935f-4e1c-a7dc-a44ddbeff740",
   "metadata": {},
   "source": [
    "This command has created the conda environment named **test_env** which contains the software specified in the yml file. \n",
    "\n",
    "In the terminal to activate a conda environment use the command `conda activate test_env`. You will see in parentheses before your prompt the text will change from `base` to `test_env`. If you are not sure what conda environments are available for you to load (or you forgot the spelling of the environment name) you can use the command `conda env list` to list the names of the available conda environments.\n",
    "\n",
    "To ensure that your conda environment is activated let's list the available software with the command `conda list`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886f04c-1bb0-4059-86ff-5cdcc2854fea",
   "metadata": {},
   "source": [
    "You can see that in addition to the software listed in the yml file, there are many additional software that have been installed. These are the software dependencies that are required to use the software programs we specified in the yml file. This is one of the strengths of using a package manager like conda - the appropriate version of each dependency required for the specified software are automatically added to your environment. \n",
    "\n",
    "If you do not have a yml file that specifies the software needed for an analysis you can create conda environments by listing the software you would like installed with the `conda create` command. Here we use the `-n` flag to specify the name of our environment, the `--channel` flag to specify the channel software packages should be loaded from, and the names of the software as the argument for the command.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c0d70-b6fa-4d6a-aba2-1885da671937",
   "metadata": {},
   "source": [
    "`conda create -n test --channel bioconda python=3.9 ipykernel fastqc -y`\n",
    "\n",
    "I know we are missing multiQC in this list of software - we will get to that later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c9d0c-8c1b-481b-b41c-138d12d51df6",
   "metadata": {},
   "source": [
    "It is easy enough to enter this command manually if you have only a small number of packages to be installed, but the command can get unwieldy if there are many packages to be installed. Furthermore, having the yml file creates some record of how the environment was created and enables you to share the file with others who may want to create and use the same environment.\n",
    "\n",
    "## Modifying a Conda Environment\n",
    "------\n",
    "\n",
    "Generally once a conda environment is created it won't need to be modified for as long as the analysis pipeline is stable. However there are times when software will need to be added, or versions of software might need to be updated. For the purpose of this lesson, I have left one of the software packages, `multiQC`, off of the list of dependencies in the \"test\" environment. Let's add this package to our environment now with the `conda install` command. Remember to first active your environment using `conda activate test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35727d5-0fbe-4d5d-a1bc-a2ce9e080af1",
   "metadata": {},
   "source": [
    "`conda install --channel bioconda multiqc -y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1bcd5-7a27-4504-970b-e8de86ee44f9",
   "metadata": {},
   "source": [
    "## Quality Control of FastQ Files\n",
    "----------\n",
    "\n",
    "Now that we have created a conda environment, let's make use of some of the tools that we installed using the looping structures that we learned about in lesson 4. The two pieces of software we will use are fastQC and multiQC - both of these softwares are for checking the quality of FASTQ files and organizing the output of quality reports to improve readability. These should have been installed in both the \"test\" and \"test_env\" environments. Make sure that one of those is activated in the terminal.\n",
    "\n",
    "### FastQC\n",
    "\n",
    "[FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) is an excellent tool that is specifically designed assess quality of FASTQ files . FastQC is composed of a number of analysis modules that calculate various QC metrics from FASTQ files (such as GC content, distribution of base quality, etc.) and summarizes this all into a nice QC report in HTML format, that can be opened in a web browser. Checking the quality of raw reads is important before you begin analyzing data as your analysis pipeline might have to be modified to mitigate poor quality data or contaminated data. \n",
    "\n",
    "\n",
    "<div style=\"display:flex\">\n",
    "     <div style=\"flex:1;padding-right:10px;\">\n",
    "          <img src=\"images/fastqc-good.png\" width=\"70%\"/>\n",
    "     </div>\n",
    "     <div style=\"flex:1;padding-left:10px;\">\n",
    "          <img src=\"images/fastqc-bad.png\" width=\"70%\"/>\n",
    "     </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "In the figure above is an example of a high quality FASTQ dataset on the left, and a poor quality FASTQ dataset on the right. You can see on the left panel of each image are a series of quality metrics. In the high quality data each of the metrics has a green check next to it, indicating the file has met the QC thresholds for that metric. In the poor quality FASTQ file some of the metrics have an orange exclamation point, and some have a red X indicating there are some issues with this data. \n",
    "\n",
    "Not all high quality data will pass all quality metrics, but generally high data will pass most of the QC metrics. Failed QC metrics are not an indication that you should toss the data and start over, rather they indicate that your analysis might need to be modified to mitigate some of the quality issues in the data. \n",
    "\n",
    "The first two quality metrics from the left panel, *Basic Statistics* and *Per base sequence quality* are also shown in the figures above. You can see that the basic statistics are very similar in the two reports, but there is a stark difference in per base sequence quality in the high quality dataset (left) and poor quality dataset (right).\n",
    "\n",
    "As a reminder quality scores indicate the confidence the base caller has in the base call that was made. A quality score of 30 indicates that there is a 0.1% chance that the base call is not accurate, a score of 20 indicates a 1% chance the base call is inaccurate. \n",
    "\n",
    "Ideally, most bases will be in the green region of the plots with a quality score of 28 or higher, and a very low probability of an inaccurate base call. This is what we see in the high quality data. In the poor quality data there are some bases in the high quality range, but the median base call at most positions is well below this threshold. Before analyzing data like this I would recommend trimming poor quality base calls, a step that isn't necessary in the high quality dataset. \n",
    "\n",
    "In both the high quality data and the poor quality data you can see that quality scores begin to drop off toward the end of the read. This is a known feature of Illumina sequencing data, the drop off is very slight in the high quality data. A significant dropoff as in the poor quality data might be an indication of issues with sample quality or the sequencing run. \n",
    "\n",
    "It is important to remember that FastQC expects a random and diverse library, and that a failure of any metric could be a feature of the experiment. Below is a table outlining what many of the metrics are measuring in the dataset, as well as the thresholds for failure. More information about these metrics can be found in the analysis modules section of the [FastQC manual](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/).\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>FastQC quality metrics and their thresholds for failing the QC metric.</th></tr>\n",
    "<tr><td><table></table>\n",
    "\n",
    "\n",
    "|Metric | Measurement | Failure threshold|\n",
    "|--- | --- | ---|\n",
    "|Per base sequence quality | Overall range in quality statistics by base position| lower quartile of quality score at any position is less than 5, or median less than 20 |\n",
    "|Per tile sequence quality | Only reported for Illumina data, average quality per flow cell tile| Any tile with a mean quality score 5 less than other tiles for a given base |\n",
    "|Per sequence quality score | Distribution of overall quality scores per read| Mean quality less than 20, corresponding to a 1% error rate |\n",
    "|Per base sequence content | The proportion of each base pair (ATGC) at each read position | difference in proportions of any base greater than 20%|\n",
    "|Per sequence GC content | GC content of reads in the library | The GC content of more than 30% of reads in the library deviate from the normal distribution |\n",
    "|Per base N content | Proportion of N base calls by position| more than 20% N base calls at any position|\n",
    "|Sequence length distribution | Distribution of read lengths | Any sequence has a length of 0|\n",
    "|Sequence duplication levels| Degree of duplication for each sequence, this metric only uses the first 100,000 reads | Duplicated sequences make up more than 50% of the library |\n",
    "|Overrepresented sequences| For each sequence making up 0.1% of the total library matches to common contaminants are reported| Any match makes up more than 1% of reads|\n",
    "|Adapter content| Proportion of reads with adapters detected at any position | Adapter sequences are present in more than 10% of reads |\n",
    "</td></tr> </table>\n",
    "\n",
    "\n",
    "Now that we have some familiarity with the report and how it can be use to inform your downstream analysis, let's take a look at the manual for FastQC to get an idea of the flags available to customize QC reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0fd77-9ea1-4f5c-a017-0463bd5c4f2b",
   "metadata": {},
   "source": [
    "`fastqc --help`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70182432-e50a-4b66-a75e-7b3b0ac97123",
   "metadata": {},
   "source": [
    "In the simplest case this tool can be used by supplying a list of fastq files to be analyzed - this will work fine for most datasets. \n",
    "\n",
    "However, reading through the help page you can see that there are a number of flags that enable you to run the analysis more efficiently. For example, you can use the `-o, --output` flag to specify the name of a directory to store QC reports from the fastqc analysis. The `-t, --threads` flag accepts an integer as an argument and can be used to speed up the analysis by using multiple threads. \n",
    "\n",
    "Let's run an analysis now and use the `-o` flag to designate a directory for the results called `fastqc`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc7cb1-76d2-4237-8d29-2882a4f3563b",
   "metadata": {},
   "source": [
    "`mkdir fastqc`\n",
    "\n",
    "`fastqc -o fastqc gcp_research_workflow/SRR1039508_1.chr20.fastq.gz gcp_research_workflow/SRR1039508_2.chr20.fastq.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f6b8e-9494-45a6-a9dc-8f9f25bc26fb",
   "metadata": {},
   "source": [
    "Take a moment to go into the fastqc file you just made and have a look at the fastqc report you generated for one of these datasets. \n",
    "\n",
    "- How do the data look, do they resemble the high quality report or the poor quality report?\n",
    "- Were any of the quality metrics flagged (orange !), or did any of them fail (red x)?\n",
    "- Were the metrics the same between the forward and reverse files?\n",
    "- Does this seem like a dataset that needs adjustment prior to an analysis, or do these data seem fairly high quality?\n",
    "\n",
    "\n",
    "\n",
    "We discussed parallelization in the first lesson, and demonstrated how it can be used to speed up an analysis. We can use the `-t` flag to parallelize a FastQC run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89933d5d-855c-4c97-9110-809c691e331f",
   "metadata": {},
   "source": [
    "`fastqc -t 2 -o fastqc gcp_research_workflow/SRR1039509_1.chr20.fastq.gz gcp_research_workflow/SRR1039509_2.chr20.fastq.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a5c00-f5fe-49cf-8331-931d469685af",
   "metadata": {},
   "source": [
    "You will notice that in the first run where we only used one thread the output indicated that the analysis analyzed each file sequentially, whereas when we used two threads the files were analyzed in parallel and finished at almost the same time. The parellelization in this case uses one thread per file so using more than two threads would not have sped up the analysis time.\n",
    "\n",
    "In many cases you will be analyzing a group of fastq files that will be compared downstream, in this case we have 4 samples in our group, samples SRR1039508, SRR1039509, SRR1039512, and SRR1039513. As we learned in the lesson beyond_basic_bash it can be helpful to use looping to perform the same function multiple times on a group of files. Use the code box below to write a loop that analyzes all of the fastq files in the `gcp_research_workflow` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2a032-4279-40dc-9824-825072cfc39e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-question-circle-o\" aria-hidden=\"true\"></i>\n",
    "    <b>TEST YOUR SKILLS</b> \n",
    "      <p>Practice your skills in the code block below</p>\n",
    "    <div style=\"background-color: white ; color:black; padding: 3px;\">Write a loop to analyze all fastq files in the gcp_research_workflow directory using 4 threads.<br><br>Multithreading doesn't speed up your analysis why?</div>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86432f8c-0cb7-4807-ae09-a69d4c6293f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## TEST YOUR SKILLS (enter and run your answers in the terminal)\n",
    "\n",
    "## Use a loop to analyze all fastq files in the gcp_research_workflow directory\n",
    "\n",
    "## Using 4 threads to analyze these files in a loop won't speed up your analysis, why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5027bd-498e-499e-9bca-ac380292535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"quiz_files/quiz5-1.html\", width=600, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364471e-7147-4254-9040-1bb2cba37143",
   "metadata": {},
   "source": [
    "The QC report that we looked at earlier, `SRR1039508_1.chr20_fastqc.html,` had a couple of warnings but mostly high passes. The warnings are flagged for metrics *per tile sequence quality*, *per sequence GC content*, and *sequence duplication levels*. These warnings could indicate a problem with the library or the run. If the problem was with only that sample, (ie. an issue with the library) then I would expect the same warnings to be present in the paired file `SRR1039508_2.chr20_fastqc.html` but not in other files from the same run. \n",
    "\n",
    "\n",
    "However, if the issue was with the sequencing run I would expect the warnings to be present in all samples in the group. Rather than click through each of the 8 HTML reports and compare the results we can use the software **MultiQC** to collate the results from all of our fastqc reports into one single report. \n",
    "\n",
    "Let's begin by looking at the help page for the MultiQC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e61bb8-7621-4b5d-9417-2fc94c7aefcb",
   "metadata": {},
   "source": [
    "`multiqc --help`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e14a1a-8dab-4fef-bff5-30f3aa9568c4",
   "metadata": {},
   "source": [
    "This help page is organized nicely to blocks indicating the categories of flags that can be used to modify the analysis and summary output of the tool.\n",
    "\n",
    "Again you can see that there are several flags that would enable you to customize the report, or the tool can be run by supplying the directories with the files to be summarized listed as arguments. MultiQC also provides the option of modifying the run with a config file `--config` rather than using multiple flags at the command line to control the format of the report. The *MultiQC* config file is similar to the yml file that we used to build our conda environment in that it serves as a record of which options were used in the command to generate the report. Additionally the config file can be used many times to generate the same format report across multiple projects.\n",
    "\n",
    "Here we are going to use the simplest case and run the tool with only the flag `--flat` to suppress the creation of interactive figures which are difficult to view in Jupyter notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b40e32-1d27-481d-a04e-9ce883620b34",
   "metadata": {},
   "source": [
    "`multiqc --flat .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395e3f9-90a0-443d-8ffe-92383f98caa4",
   "metadata": {},
   "source": [
    "\n",
    "If you double click the html file called `multiqc_report.html` you will notice as with the fastqc report there are links on the left of the file that will enable you to navigate to that section of the report quickly. Unlike the fastqc report these links are not colored according to warnings, but all samples within the directory are summarized in one single report. Perhaps more useful than flagged metrics in the fastqc report is the ability to look for consistency across samples that will be analyzed as a group. You can see in the screen shot of the report below that all samples are grouped into a single report.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/multiqc.png\" alt=\"multiqc\" width=\"80%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "We can see that there is some slight variation in sample size, but all of our samples are very high quality with base quality scores above 30 even at the end of the read. \n",
    "\n",
    "Perhaps most importantly, and easiest to see in the coallated report is that all samples are consistent with each other in all metrics, similar GC content, duplication rates, and quality score distributions. The small variation in library sizes is expected and can be mitigated with the normalization methods of most RNAseq differential expression software so should not pose a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a212eeb-7070-4643-b483-b429af3656c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "    <b>Alert: </b> To fully interact with a HTML file don't forget to click the <img src=\"images/trust_html.png\" alt=\"trust HTML\" width=\"10%\"/> button on the top left side of the HTML viewer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c434f-3034-44ab-bee5-7a24c9fe1700",
   "metadata": {},
   "source": [
    "## Gemini (Optional)\n",
    "--------\n",
    "\n",
    "If you're having trouble with this submodule (or others within this tutorial), feel free to leverage Gemini by running the cell below. Gemini is Google's advanced generative AI model designed to enhance the capabilities of AI applications across various domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369402c-f542-493b-91f7-85af7a8f96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have the necessary libraries installed\n",
    "!pip install -q google-generativeai google-cloud-secret-manager\n",
    "!pip install -q git+https://github.com/NIGMS/NIGMS-Sandbox-Repository-Template.git#subdirectory=llm_integrations\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "import sys\n",
    "import os\n",
    "util_path = os.path.join(os.getcwd(), 'util')\n",
    "if util_path not in sys.path:\n",
    "    sys.path.append(util_path)\n",
    "\n",
    "from gemini import run_gemini_widget, create_gemini_chat_widget \n",
    "from IPython.display import display\n",
    "\n",
    "run_gemini_widget()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
