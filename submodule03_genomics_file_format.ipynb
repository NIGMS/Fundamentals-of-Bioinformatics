{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3347b3e2-329b-4ceb-9829-51ab1e2a3cb5",
   "metadata": {},
   "source": [
    "# Standard Genomics File Formats\n",
    "------\n",
    "### Learning Objectives:\n",
    "\n",
    "+ Learn the standard file formats of three common genomics file types\n",
    "    + GFF files for storing genomic annotation data\n",
    "    + Fasta files for storing assembled sequence data\n",
    "    + Fastq files for storing raw read data\n",
    "\n",
    "+ Learn basic BASH coding to explore file contents\n",
    "\n",
    "+ Learn to build complex BASH code  by combining basic BASH commands\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbeaea5-8155-4ed4-b951-e641f533be7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genomic Annotation Data, GFF/GTF file Format\n",
    "------\n",
    "The standard genomic annotation format is called a GFF/GTF file, this is a tab delimited (tsv) file that indicates the positions of genomic features of interest in a genome. \n",
    "\n",
    "Features of interest could be genes, transcripts, non-coding RNA, tRNA, rRNA, 3'-UTRs, and more. When building a GFF file you have the option to select the features annotated. Most files include at least genes, transcripts, tRNA, and rRNA. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/gtf.png\" width=\"100%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>GFF files all have 9 tab delimited fields, as shown in the figure above. Each field is described briefly below.</th></tr>\n",
    "<tr><td><table></table>\n",
    "\n",
    "\n",
    "|Column number | Column name | Column description|\n",
    "|--- | --- | ---|\n",
    "|Column 1 | Seqname | The sequence ID being annotated, usually the chromosome or scaffold name|\n",
    "|Column 2 | Source | The source of the annotations, usually the software used to annotate features|\n",
    "|Column 3 | Feature type | The type of feature annotated|\n",
    "|Column 4 | Start | The starting coordinate of the feature|\n",
    "|Column 5 | End | The end coordinate of the feature|\n",
    "|Column 6 | Score | The score of the feature, this could be an e-value or p-value depending on the annotation software|\n",
    "|Column 7 | Strand | + for positive strand (relative to the landmark), - for minus strand, and . for features that are not stranded|\n",
    "|Column 8 | Frame | For features of type \"CDS\", the frame can be 0, 1, or 2, indicating the number of bases forward from the start of the current CDS feature the next codon begins|\n",
    "|Column 9 | Feature attributes | A list of feature attributes in the format tag=value. Multiple tag=value pairs are separated by semicolons|\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "\n",
    "There is a gff format file in the `gcp_research_workflow` directory (downloaded in lesson 2) that is an annotation file for the Sars-CoV2 genome called `gcp_research_workflow/sequence.gff3`. let's have a look at this file to familiarize ourselves with the file format and some ways to work with this format in the terminal environment. \n",
    "\n",
    "#### wc\n",
    "\n",
    "To start we will use the *word count* `wc` command with the flag `-l` to indicate we would like to know how many lines are in the file. As you can see from the example figure there will be one line for each annotated feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679ac14-0ac9-45d5-bb0a-b1a7f8b8ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# let's count the lines in the file\n",
    "# We will use the \"wc\" command with the \"-l\" flag to indicate we want to count the number of lines in the file\n",
    "wc -l gcp_research_workflow/sequence.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2577856-d3b6-494d-b3ee-a4652ed87882",
   "metadata": {},
   "source": [
    "#### cut\n",
    "\n",
    "Sars-CoV2 is a virus, and thus has a pretty small genome and a limited number of features. Now we will use the `cut` command to see which features are annotated in this file. By default `cut` will use the tab to delimit columns and the flag `-f` can be used to select a column of interest to print to the screen. Remember the type of feature is listed in the third column, so we will use `cut -f3` to pull the information from the third column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c5656-4202-4ecd-bd27-a0b62757b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Now let's isolate the information in the 3rd column to check what type of features are annotated in this genome\n",
    "# We will use the \"cut\" command with the \"-f\" flag to pull out the thrid column\n",
    "cut -f 3 gcp_research_workflow/sequence.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dd982-f6b5-4fba-805b-c1cd1a99bad5",
   "metadata": {},
   "source": [
    "\n",
    "Most of the annotated features are coding sequences with some non-coding features annotated. If we were interested in which features were annotated in this file the information is here, but it is poorly organized with this command. We can build on the command we used above using the *pipe* `|` which takes the output from the command on the left of the pipe and sends it as input to the command on the right of the pipe. \n",
    "\n",
    "#### sort\n",
    "\n",
    "Here we can combine the `cut -f3` command we used earlier with a `sort` command using the flag `-u` to report each unique value only once and produce a concise list of features annotated in the file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de1f37-48dd-4c31-a7ea-bce1620b5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# That is a long list, let's use the \"|\" which enables us to link commands where the output of the command on the left of the pipe becomes the input for the command on the right of the pipe\n",
    "# We will combine our earlier command with the \"sort\" command and the \"-u\" flag to reduce the list to one line for each unique entry in the column\n",
    "cut -f 3 gcp_research_workflow/sequence.gff3|sort -u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d4544-7f90-4bfc-b530-1d422fa87728",
   "metadata": {},
   "source": [
    "\n",
    "The output of this command provides a more clear and organized list of the types of features annotated in this file. You can see there are seven types of features annotated in this file. \n",
    "\n",
    "#### grep\n",
    "\n",
    "Next let's pull out the annotation lines that correspond to coding sequences, feature type *CDS*, with the command `grep`. The `grep` command is a powerful tool for searching for text strings in a file. The syntax of the `grep` command is `grep PATTERN FILENAME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b59b50-990d-43b2-99b5-42eb06e71a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Use the grep command to isolate CDS features\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d5cfa-0142-45f1-b7d6-022851b1eec1",
   "metadata": {},
   "source": [
    "\n",
    "There are quite a few lines there, and a lot of information on each line. let's combine the `grep` command with a `cut` command to pull out the genome name, start position, and stop position for each coding sequence in this file. Remember the genome name is the first field, the start position is the fourth field, and the stop position is the fifth field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c50d2-6930-4c41-9308-8e8b1bdc5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Lastly we will save the output to a new text file with the redirect command \">\" \n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f1,4,5 > ref_locations.txt\n",
    "\n",
    "# Take a look at the first couple lines of the output file\n",
    "head -n3 ref_locations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f64168-126e-459a-b2dd-1e7248c29c26",
   "metadata": {},
   "source": [
    "The output in this format is certainly less noisy but could use some more annotation. \n",
    "\n",
    "Let's add the annotation information which is part of the feature attributes column, the ninth column in this file. This column contains a lot of information and each attribute is in the format *tag=value* and separated from the next attribute by a semi-colon. Some attributes are missing in some of the coding sequence entries, meaning there are a different number of `;` on each line and we won't be able to simply use the `cut` command as we did with the position information. However, each line has a *product* annotation as the second to last attribute. We can build a fairly complex command with `|` to isolate the annotation for each coding sequence. Here are the steps of the command in the video below:\n",
    "\n",
    "<span style=\"color:black\">Learn more about piping commands in [this video](https://www.youtube.com/watch?v=J5dmCAYOh9Q&list=PLXaEJPtnQ4w7Vu7vqWbttBjUGrPp4Qa7b&index=4)</span>\n",
    "\n",
    "1. `grep \"CDS\" gcp_research_workflow/sequence.gff3` pull the lines that have the pattern \"CDS\"\n",
    "2. `cut -f 9` isolate the ninth field of the output from step 1\n",
    "3. `rev` reverse the output from step 2 so the last letter is first, etc.\n",
    "4. `cut -d \";\" -f 2` cut using the \";\" as the delimiter instead of the tab and take the second field\n",
    "5. `rev` reverse the string again so that the string is readable\n",
    "6. `cut -d \"=\" -f 2` cut using the \"=\" as the delimited and take the second field\n",
    "7. `>products.txt` save the output to the file products.txt\n",
    "\n",
    "Use the coding fields below so you can see the output of each step as we build the complexity of the command. Each of these commands (except the last one) ends in the `head -n1` command to limit the output to 1 line and improve the readability of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8b4e7-50d0-427b-ae60-3120b29442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 1\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|head -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7028c7-0f63-4f57-8bab-ca1be93cec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 2\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|head -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf8f2d-a0b1-4a59-8211-3318d6652630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 3\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|rev|head -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceafc8c-1bab-4a6f-931f-89efac7260de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 4\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|rev|cut -d \";\" -f2|head -n1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d900f-e82f-41f1-90fb-93fd82b4b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 5\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|rev|cut -d \";\" -f2|rev |head -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ea8e2-60ba-43c2-a2a4-c4a60773dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 6\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|rev|cut -d \";\" -f2|rev|cut -d \"=\" -f2|head -n1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577b8e1-ff2d-4860-8340-e5a8f22ad469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Putting it all together and saving it to a file\n",
    "grep \"CDS\" gcp_research_workflow/sequence.gff3|cut -f9|rev|cut -d \";\" -f2|rev|cut -d \"=\" -f2> products.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7e3d6-d804-4d9c-a00f-1ca50b147efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head products.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc56610-43de-433b-85c3-6425aaea401d",
   "metadata": {},
   "source": [
    "\n",
    "You can see how using the pipe `|` enables you build pretty complex commands by repeating a series of simpler commands on the output of previous commands. Now let's add our annotations to our location information to create a file with the positions and annotation information for all coding sequences from the Sars-CoV2 genome. \n",
    "\n",
    "For this we will use the `paste` command, this command paste the contents of files together. By default the contents of each file will be pasted together with a tab, however as with `cut` this can be modified with the `-d` flag. Here we will use the default to paste together the information from CDS annotation lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc00331-2d69-49ba-8e49-047cb81566d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Lastly let's combine the files we made with the \"paste\" command\n",
    "paste ref_locations.txt products.txt > cds_info.txt\n",
    "\n",
    "# let's look at our new file \n",
    "head cds_info.txt\n",
    "\n",
    "# Much easier to read!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33c67a-1ef0-4491-b59d-776dfff623a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genomic Sequence Data, Fasta Files\n",
    "----------------\n",
    "\n",
    "Fasta files are used to store various types of 'long form' genomic data. Fasta files most often contain genomic sequences in either nucleotide or amino acid data, but the fasta file format can also be used to store phenotypic data of a given organism.\n",
    "\n",
    "Regardless of the sequence alphabet the format of a fasta file is defined by two types of lines:\n",
    "1. A header line begins with the `>` character and has a description of the sequence on the lines that follow\n",
    "2. A sequence line contains the characters of the sequence described by the header line\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fasta.png\" width=\"70%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "--------------\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fasta1.png\" width=\"70%\"/>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28afc24e-5aa1-4c28-ac53-c16f67f10f8f",
   "metadata": {},
   "source": [
    "#### Decoding the Contents of a Fasta File\n",
    "\n",
    "Fasta files containing sequence data can be of many different types. Whole genome sequences, assembled scaffolds from reads, aligned protein sequences, or a collection of coding sequences from an organisms are several examples of the types of data you can find in a fasta file. \n",
    "\n",
    "Hopefully not often, but from time to time you may come across a fasta file you would like to work with, but are unsure of the contents of the file. There are a couple of features of various data types that you can use to determine the contents of the file. \n",
    "\n",
    "There are almost always more sequence lines than header lines in a fasta file, but data like annotated coding sequences and sequence alignments will have more header lines than files containing assembled scaffolds or complete genome data. In most complete genome fasta files and very good assembled scaffolds you will have only 1 or 2 header lines with many lines of sequence data. \n",
    "\n",
    "In the examples above you can see that at times the header doesn't contain much information as in the example at the top of the figure. However, the example at the bottom of the figure provides an accession number, a description of the protein, and the species the sequence came from. This second example is a very good example of what information is helpful to include in a sequence header. \n",
    "\n",
    "One last feature is the alphabet of letters in the sequence data. As I mentioned earlier there are rare cases where a fasta file encodes phenotypic characters and in those cases you will see mostly binary characters 1 and 0 in the sequence lines, but this is rare. Most sequences will be either nucleotide sequences or protein sequences, and these are pretty easily distinguished by their very different alphabets. The sequences in the top half of the figure above are nucleotide data in the fasta file  format, this is clear from the limited sequence alphabet (*ATCG*). Sequences in the bottom half of the figure are in the protein format, indicated by the expanded sequence alphabet (*ACDEFGHIKLMNPQRSTVWY*). \n",
    "\n",
    "\n",
    "I have added two unlabeled fasta files with sequence data to the directory `gcp_research_workflow`. let's look at some of the features we outlined above to determine the contents of each file, and then rename the files so that we have a better system for knowing what each file contains. \n",
    "\n",
    "Start by determining how many lines are in the file with the word count `wc` command using the flag `-l`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5754551-bf07-4025-8d8e-ac5cbbfd95a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# List the number of lines in the first fasta file with the word count (wc) command \n",
    "# Using the flag \"-l\" indicate you want to know how many lines (rather than words) are in the file\n",
    "\n",
    "wc -l gcp_research_workflow/sequence-1.fasta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec83f4-4f42-4fb2-aa3b-c38a45a92796",
   "metadata": {},
   "source": [
    "Next we want to know how many of the total lines in the file are header lines beginning with the `>` symbol. For this we will use the search command `grep`. As you saw in the sections above, this command is useful for isolating interesting information from a large file. We can extend the utility of this command even further by combining it with a regular expression. \n",
    "\n",
    "\n",
    "#### Regular Expressions\n",
    "\n",
    "Regular expressions are symbols in coding languages that stand for a pattern. The meaning of many regular expressions are preserved across multiple coding languages because they are useful in so many aspects of coding. \n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>Commonly used regular expressions.</th></tr>\n",
    "<tr><td><table></table>\n",
    "    \n",
    "|Operator | Effect|\n",
    "|---|---|\n",
    "|\\* | wildcard stands for any number of anything|\n",
    "|^ | start of the line|\n",
    "|$ | end of the line|\n",
    "|[0-9] or \\d| any number (0123456789)|\n",
    "|[a-z]| any lowercase letter|\n",
    "|[A-Z]| any uppercase letter|\n",
    "|\\t | a tab|\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "\n",
    "To count the number of times a feature was annotated in a GFF file as either the 5'-UTR or the 3'-UTR I could use the following command:\n",
    "\n",
    "`grep -c \"[0-9]'-UTR\" sequence.gff`\n",
    "\n",
    "The `-c` flag would return a count of the number of times the patterns 0'-UTR, 1'-UTR, 2'-UTR, 3'-UTR, 4'-UTR, 5'UTR, 6'-UTR, 7'-UTR, 8'-UTR, and 9'-UTR were found in the file. Of course only 5'-UTR and 3'-UTR would be found but the regular expression is looking for any number before the rest of the pattern provided to the `grep` command.\n",
    "\n",
    "Here we can use the regular expression `^` with the `grep -c` command to count lines where the pattern `>` is found at the start of the line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991d53a-cefb-40b9-8807-f819434d7afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Check how many lines start with the \">\" character in the first file\n",
    "# The grep command will print out the lines that match the pattern we are looking for\n",
    "# Notice that the pattern I'm looking for (in quotes) uses the regular expression `^` to indicate that I want lines that begin with the \">\" \n",
    "# Using the `-c` flag with the grep command will count the number of lines that match that pattern\n",
    "grep -c \"^>\" gcp_research_workflow/sequence-1.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c23a46-fa80-4543-82e7-82e9799a7ffe",
   "metadata": {},
   "source": [
    "In this case about half of the lines of this file are header lines, that is they begin with `>`, and the other half are sequence lines. It is unlikely with this ratio of sequence to header lines that this file contains a whole genome or an assembly scaffold.\n",
    "\n",
    "Next, we can check to see if there is useful information in the header lines. Here we can use the `grep` command again with the regular expression to isolate the header lines, but this time for ease of interpretation we will limit the matches returned by grep with the `-m` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0afae-b57f-47ed-9f0c-ad445286dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Using the `-m 3` flag with the grep command will only return the first 3 matches (or whatever number you type after the flag)\n",
    "grep -m 3 \"^>\" gcp_research_workflow/sequence-1.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5087e87-20dc-4cc6-9f9f-f835ca60de60",
   "metadata": {},
   "source": [
    "#### head, tail, cat, & more\n",
    "\n",
    "Here we can see that the header lines indicate the species the sequences come from, and there are three different species listed, but there isn't any description of the sequence content in the header beyond that. let's look at some of the sequence data with the `head` and `tail` commands to determine what type of data is in this file. \n",
    "\n",
    "We could look at the contents of the files with the `cat` command, which prints all lines of the file to the screen. For small files this is okay, but for larger files like fasta files this amount of output can be overwhelming and not very useful. \n",
    "\n",
    "One more way to view the contents of a file is the `more` command which displays data one \"screenfull\" of lines at a time (the number of lines depends on the size of your screen and the font size). This command is interactive so it won't work in the Jupyter notebook, but is very useful for scrolling through data in the terminal window. The `space-bar` key will 'scroll' one line at a time and the `return` key will 'scroll' one screen full  of lines at a time. If you would like to stop scrolling and return to your prompt use the `ctrl + C` keys. The `ctrl +C` is a universal signal to the terminal that you would like to abort the command that is currently running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde4a80-e24b-46e0-ae0e-e003315d1256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The head command by default shows only the first ten lines of the file\n",
    "# You can adjust the number of lines shown with the flag `-n 6` for the first 6 lines\n",
    "head -n 6 gcp_research_workflow/sequence-1.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7d7ff-daeb-4974-bf37-c1e7e4c0353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The tail command by default shows the last ten lines of the file \n",
    "# You can be adjust the number of lines shown with the `-n 20` flag to show the last 20 lines of the file\n",
    "tail -n 20 gcp_research_workflow/sequence-1.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6610f-52db-4d00-a354-81c2fddada07",
   "metadata": {
    "tags": []
   },
   "source": [
    "The sequence alphabet of this file indicates that these are protein sequences and you'll notice that each sequences is about the same length. There isn't a lot of information in the headers, but we can see that each sequence comes from a different species and we know that there are the same number of headers and sequence lines. Together this information indicates that these sequences are from a protein alignment. To be sure we can use NCBI's [BLAST tool](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastp&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome) to check the identity of some of these sequences.  \n",
    "\n",
    "To save you the trouble I will tell you this file is a multi-sequence alignment of the S11 ribosomal protein from various proteobacteria. Now that we know what this file is, let's copy it into a new directory  with the command `cp`. The syntax of this command is similar to the copy command we used to copy the files from the Google bucket to your Jupyter notebook, `cp SOURCE DESTINATION` as before we will replace the arguments with paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642d6d7-53b8-4cc5-bb4a-79f44d7cd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Make a directory to store annotated sequence data\n",
    "mkdir new_dir\n",
    "\n",
    "# Copy the file \"sequence-1.fasta\" into the directory you made called new_dir\n",
    "cp gcp_research_workflow/sequence-1.fasta new_dir/\n",
    "\n",
    "# Check to see that the file was copied\n",
    "ls new_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc5d19a-b5ab-42b8-9961-afca5f8f95cb",
   "metadata": {},
   "source": [
    "#### mv\n",
    "\n",
    "Now let's rename the file to something that is more descriptive like `S11_proteobacteria_proteins.fasta`. We can rename files with the `mv` command. This is flexible in that the activity of the command is dictated by the types of arguments provided. The command can be used to move files by using the command syntax `mv SOURCE DESTINATION` or it can be used to rename files by using the syntax `mv CURRENTFILENAME NEWFILENAME`. Here we provide 2 filenames as arguments, so the command will rename the first file with the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c311062-18c8-419a-9fe8-988e8513f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Rename the file with mv command\n",
    "mv new_dir/sequence-1.fasta new_dir/S11_proteobacteria_proteins.fasta\n",
    "\n",
    "# Check to see that the name has changed\n",
    "ls new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9b83e-dbfa-4bb8-9444-53aad640dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Move the sequence-1 file from gcp_research_workflow to new_dir\n",
    "mv gcp_research_workflow/sequence-1.fasta new_dir/\n",
    "\n",
    "# Check to see that the file has moved\n",
    "ls new_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a9a33-a7b0-462a-9d16-edf55e8e5ddd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-question-circle-o\" aria-hidden=\"true\"></i>\n",
    "    <b>TEST YOUR SKILLS</b> \n",
    "      <p>Practice your skills in the code block below</p>\n",
    "    <div style=\"background-color: white ; color:black; padding: 3px;\"> 1. List the number of lines in each fasta file with the word count (wc) command <br> 2. Using the flag \"-l\" indicate you want to know how many lines (rather than words) are in the file <br>3. Using the `-c` flag with the grep command will count the number of lines that match that pattern <br>4. Using the `-m 3` flag with the grep command will only return the first 3 matches (or whatever number you type after the flag)<br>5. The head command by default shows only the first ten lines of the file but you can adjust the number of lines shown with the flag `-n 100` for the first 100 lines.<br><br> Run the #FLASHCARD code block to see the answer.</div>\n",
    "    \n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a8d4a-77fa-49ce-945b-6990d685348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# TEST YOUR SKILLS (enter and run your answers here)\n",
    "\n",
    "# List the number of lines in each fasta file with the word count (wc) command \n",
    "\n",
    "# Using the flag \"-l\" indicate you want to know how many lines (rather than words) are in the file\n",
    "\n",
    "# Using the `-c` flag with the grep command will count the number of lines that match that pattern\n",
    "\n",
    "# Using the `-m 3` flag with the grep command will only return the first 3 matches (or whatever number you type after the flag)\n",
    "\n",
    "# The head command by default shows only the first ten lines of the file but you can adjust the number of lines shown with the flag `-n 100` for the first 100 lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21493d90-492e-4324-a15e-3916718ee64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLASHCARD\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"quiz_files/quiz3-1.html\", width=600, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4c02a-b675-4f96-85c8-fc54c3329480",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Raw Sequencing Data, FASTQ Files\n",
    "------------------------------\n",
    "\n",
    "FASTQ files are arguably the workhorse file format of bioinformatics. FASTQs are used to store sequence reads generated in next-generation sequencing (NGS) experiments. Similarly to FASTA files, FASTQ files contain a header line, followed by the sequence read, however individual quality scores of base calls from the sequencer are included for each record in a FASTQ file.\n",
    "\n",
    "Here is what a the first record of an example FASTQ file looks like\n",
    "```\n",
    "@SRR1039508.1 HWI-ST177:290:C0TECACXX:1:1101:1225:2130 length=63\n",
    "CATTGCTGATACCAANNNNNNNNGCATTCCTCAAGGTCTTCCTCCTTCCCTTACGGAATTACA\n",
    "+\n",
    "HJJJJJJJJJJJJJJ########00?GHIJJJJJJJIJJJJJJJJJJJJJJJJJHHHFFFFFD\n",
    "```\n",
    "\n",
    "**Four rows exist for each record in a FASTQ file:**\n",
    "- **Row 1:** Header line that stores information about the read (always starts with an `@`), such as the *instrument ID*, *flowcell ID*, *lane on flowcell*, *file number*, *cluster coordinates*, *sample barcode*, etc.\n",
    "- **Row 2:** The sequence of bases called\n",
    "- **Row 3:** Usually just a `+` and sometimes followed by the read information in line 1\n",
    "- **Row 4:** Individual base qualities (must be same length as line 2)\n",
    "\n",
    "Quality scores, also known as **Phred scores**, in row 4 represent the probability that the associated base call is incorrect. A base with a Phred score of `10` has a `1 in 10` chance of being an incorrectly called base, or *90%*, as in the table below:\n",
    "\n",
    "Phred Score | Probability of incorrect call | Accuracy\n",
    "-------|-------|-------\n",
    "10 | 1 in 10 | 90%\n",
    "20 | 1 in 100 | 99%\n",
    "30 | 1 in 1000 | 99.9%\n",
    "40 | 1 in 10,000 | 99.99%\n",
    "50 | 1 in 100,000 | 99.999%\n",
    "60 | 1 in 1,000,000 | 99.9999%\n",
    "\n",
    "\n",
    "However, we can clearly see that the fourth line does not list probabilities. Instead, quality scores are encoded by a character that is associated with an **ASCII (American Standard Code for Information Interchange)** characters. ASCII codes provide a convenient way of representing a number with a character.\n",
    "\n",
    "In FASTQ files, Q-score is linked to a specific ASCII character by **adding 33 to the Phred-score**, and matching the resulting number with its *ASCII* character according to the standard code.\n",
    "\n",
    "| Symbol | ASCII Code | Q-Score |\n",
    "|--------|------------|---------|\n",
    "| !      | 33         | 0       |\n",
    "| \"      | 34         | 1       |\n",
    "| #      | 35         | 2       |\n",
    "| $      | 36         | 3       |\n",
    "| …      | …          | …       |\n",
    "| ?      | 63         | 30      |\n",
    "| @      | 64         | 31      |\n",
    "| A      | 65         | 32      |\n",
    "| …      | …          | …       |\n",
    "\n",
    " You can see the full table [here](https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm). This encoding means that quality scores only take up **1 byte per value** in the FASTQ file (saves disk space).\n",
    "\n",
    "For example, the first base call in our sequence example above, the `C` has a quality score encoded by an `H`, which corresponds to a Q-score of 34, meaning this is a good quality base call.\n",
    "\n",
    "\n",
    "In contrast, you can see a stretch of `#`s indicating a Q-score of 2. Looking at the FASTQ record (line 2), these correspond to a string of `N` calls, which are bases that the sequencer was not able to make a base call for.\n",
    "\n",
    "**Paired-end reads:**  \n",
    "If you sequenced paired-end reads, you will have two FASTQ files:  \n",
    "**..._R1.fastq** - contains the forward reads  \n",
    "**..._R2.fastq**- contains the reverse reads  \n",
    "\n",
    "Most downstream analysis tools will recognize that such files are paired-end, and the reads in the forward file correspond to the reads in the reverse file, although you often have to specify the names of both files to these tools.\n",
    "\n",
    "It is critical that the R1 and R2 files have **the same number of records in both files**. If one has more records than the other, which can sometimes happen if there was an issue in the demultiplexing process, you will experience problems using these files as paired-end reads in downstream analyses.\n",
    "\n",
    "\n",
    "Normally to check the quality of a fastQ file one would use software designed for that purpose, but it is useful to be able to manipulate FASTQ files if you are going to be doing lots of bioinformatics.\n",
    "\n",
    "Due to their large size, we often perform `gzip` compression of FASTQ file. However this means we have to unzip them if we want to look inside them and perform operations on them. We can do this with the `zcat` command and a pipe (|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c305-92c8-4843-aecb-5016b79af777",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# \"zcat\" lists the contents of a zipped file to your screen, and head limits the output to the first ten lines.\n",
    "\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | head\n",
    "zcat gcp_research_workflow/SRR1039508_2.chr20.fastq.gz | head\n",
    "\n",
    "# Use the \"wc -l\" command to determine how many reads we have in total (don't forget to divide by 4 as each read has 4 lines affiliated with it)\n",
    "# Paired-end reads should have the same number of records!\n",
    "\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | wc -l\n",
    "zcat gcp_research_workflow/SRR1039508_2.chr20.fastq.gz | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab7310-7568-4cf2-8a01-b33b431caadf",
   "metadata": {},
   "source": [
    "#### sed\n",
    "\n",
    "Now let's determine the number of times the sequencer was not able to determine the base call for the first 10,000 reads. To do this we need to extract the sequence lines from the fastq entries, we will use the `sed` command to isolate the second line (sequence line) of each of the first 10,000 reads.\n",
    "\n",
    "1. `sed`'s' `'p'` argument tells the program we want the output to be printed, and the `-n` option to tell sed we want to suppress automatic printing (so we don't get the results printed 2x). We specify `'2~4p'` as we want sed to *print the 2cnd line, then skip forward 4* to the next line of sequence. \n",
    "2. `grep` command with the `-o` flag to separate each letter (base pair) onto it's own line \n",
    "3. `sort` command sorts the letters alphabetically\n",
    "4. `grep` again isolates lines with a base call of **N** \n",
    "5. `uniq -c` to count the number of times N was called in the first 10,000 reads. \n",
    "\n",
    "Whew .. it's a long command with a lot going on. I really encourage you to play with this command and see what the output looks as you add each successive pipe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d247d-0324-45e7-b560-1dac43a64f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 1\n",
    "# Print the first 10,000 reads\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338065f-bd19-43ec-8af3-95f2258fd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 2\n",
    "# Print each base from the first 10,000 reads to it's own line\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f514af-db18-4c01-87bd-0d8c42a9dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 3\n",
    "# Sort the bases from the first 10,000 reads\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc47a8-b71d-415c-a94d-74380c13193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 4\n",
    "# Isolate the \"N\" bases from the first 10,000 reads\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | sort | grep 'N' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8aee2-957c-4fd1-b1d0-f669cbae1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Step 5\n",
    "# Count the number of \"N\" bases from the first 10,000 reads\n",
    "zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | sort | grep 'N' | uniq -c\n",
    "\n",
    "\n",
    "## One of the maddening things about learning to code is that there are many ways to get to the same answer here are four other ways we could have gotten the same answer, test them out! \n",
    "\n",
    "# Count the number of \"N\" bases from the first 10,000 reads\n",
    "# zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | sort | grep 'N' | wc -l\n",
    "\n",
    "# count the number of \"N\" bases from the first 10,000 reads\n",
    "# zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | sort | grep -c 'N'\n",
    "\n",
    "# count the number of \"N\" bases from the first 10,000 reads\n",
    "# zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | grep 'N' | wc -l\n",
    "\n",
    "# count the number of \"N\" bases from the first 10,000 reads\n",
    "# zcat gcp_research_workflow/SRR1039508_1.chr20.fastq.gz | sed -n '2~4p' | head -n 10000 | grep -o . | grep -c 'N'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dc953-43cb-4323-a020-2b8105f5f46e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-question-circle-o\" aria-hidden=\"true\"></i>\n",
    "    <b>TEST YOUR SKILLS</b> \n",
    "      <p>Practice your skills in the code block below</p>\n",
    "    <div style=\"background-color: white ; color:black; padding: 3px;\">Try editing the command above to check how many bases have a Q-score of 2 in the first 10,000 reads.<br><br> HINT: Use the table above to remind yourself of the ASCII symbol for Q-score =2 and remember the Q score is on the 4th line.<br><br> Run the #FLASHCARD code block to see the answer. </div>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda2fac-11bd-40b8-920f-45978fc60d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## TEST YOUR SKILLS (enter and run your answers here)\n",
    "\n",
    "# Try editing the command above to check how many bases have a Q-score of 0 in the first 10,000 reads\n",
    "\n",
    "# Use the table above to remind yourself what the ASCII symbol for Q-score =2 is \n",
    "\n",
    "# Remember the Q score is on the fourth line not the second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436fa79-5369-404d-86ee-f0a166f07aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLASHCARD\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"quiz_files/quiz3-2.html\", width=600, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01f87a-0f27-4c38-a530-254edc65e8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
